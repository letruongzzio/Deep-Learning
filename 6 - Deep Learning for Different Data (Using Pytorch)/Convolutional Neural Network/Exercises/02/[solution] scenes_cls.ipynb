{"cells":[{"cell_type":"markdown","metadata":{"id":"Ls3L9w-mG9Zq"},"source":["## 0. Download dataset\n","**Note:** If you can't download using gdown due to limited number of downloads, please download it manually and upload it to your drive, then copy it from the drive to colab.\n","```python\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","!cp /path/to/dataset/on/your/drive .\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XR2hDC-kBMyd"},"outputs":[],"source":["# https://drive.google.com/file/d/1QEGqmIP0pxQuATj1aqmyW1Fk1suq7LYK/view?usp=drive_link\n","!gdown --id 1QEGqmIP0pxQuATj1aqmyW1Fk1suq7LYK"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JveOJG8XH33s"},"outputs":[],"source":["!unzip img_cls_scenes_classification.zip"]},{"cell_type":"markdown","metadata":{"id":"EQeJEySoG_Qx"},"source":["## 1. Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_s_9iDJHNMJ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"Vf2wyW6hH6LM"},"source":["## 2. Read dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aky_tAMuNT12"},"outputs":[],"source":["root_dir = 'dataset/scenes_classification'\n","train_dir = os.path.join(root_dir, 'train')\n","test_dir = os.path.join(root_dir, 'val')\n","\n","X_train = []\n","y_train = []\n","X_test = []\n","y_test = []\n","classes = {\n","    label_idx: class_name \\\n","        for label_idx, class_name in enumerate(\n","            sorted(os.listdir(train_dir))\n","        )\n","}\n","for dataset_path in [train_dir, test_dir]:\n","    for label_idx, class_name in classes.items():\n","        class_dir = os.path.join(dataset_path, class_name)\n","        for img_filename in os.listdir(class_dir):\n","            img_path = os.path.join(class_dir, img_filename)\n","            if 'train' in dataset_path:\n","                X_train.append(img_path)\n","                y_train.append(label_idx)\n","            else:\n","                X_test.append(img_path)\n","                y_test.append(label_idx)"]},{"cell_type":"markdown","metadata":{"id":"W71YwGLtTb1C"},"source":["## 3. Train, val, test split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDhW8oB3Sl3X"},"outputs":[],"source":["seed = 0\n","val_size = 0.2\n","is_shuffle = True\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train, y_train,\n","    test_size=val_size,\n","    random_state=seed,\n","    shuffle=is_shuffle\n",")"]},{"cell_type":"markdown","metadata":{"id":"iXx3le_nTe7K"},"source":["## 4. Create pytorch dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKoGy1rhH7ol"},"outputs":[],"source":["class ScenesDataset(Dataset):\n","    def __init__(\n","        self,\n","        X, y,\n","        transform=None\n","    ):\n","        self.transform = transform\n","        self.img_paths = X\n","        self.labels = y\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img_paths[idx]\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, self.labels[idx]"]},{"cell_type":"markdown","metadata":{"id":"N87jYgtTVEaW"},"source":["## 5. Create data preprocessing function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urcklIg-VKT_"},"outputs":[],"source":["def transform(img, img_size=(224, 224)):\n","    img = img.resize(img_size)\n","    img = np.array(img)[..., :3]\n","    img = torch.tensor(img).permute(2, 0, 1).float()\n","    normalized_img = img / 255.0\n","\n","    return normalized_img"]},{"cell_type":"markdown","metadata":{"id":"BJWxpyFVVIQC"},"source":["## 6. Create dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2INWkQ2UxCE"},"outputs":[],"source":["train_dataset = ScenesDataset(\n","    X_train, y_train,\n","    transform=transform\n",")\n","val_dataset = ScenesDataset(\n","    X_val, y_val,\n","    transform=transform\n",")\n","test_dataset = ScenesDataset(\n","    X_test, y_test,\n","    transform=transform\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MooDikjcWquF"},"outputs":[],"source":["train_batch_size = 64\n","test_batch_size = 8\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=train_batch_size,\n","    shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tC5_s8vvc23j"},"outputs":[],"source":["train_features, train_labels = next(iter(train_loader))\n","print(f'Feature batch shape: {train_features.size()}')\n","print(f'Labels batch shape: {train_labels.size()}')\n","img = train_features[0].permute(1, 2, 0)\n","label = train_labels[0].item()\n","plt.imshow(img)\n","plt.axis('off')\n","plt.title(f'Label: {classes[label]}')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"cqgmcSFifl01"},"source":["## 7. Create model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvNKVPY6mStX"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class BottleneckBlock(nn.Module):\n","    def __init__(self, in_channels, growth_rate):\n","        super(BottleneckBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_channels)\n","        self.conv1 = nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n","        self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        res = x.clone().detach()\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.conv1(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = torch.cat([res, x], 1)\n","\n","        return x\n","\n","class DenseBlock(nn.Module):\n","    def __init__(self, num_layers, in_channels, growth_rate):\n","        super(DenseBlock, self).__init__()\n","        layers = []\n","        for i in range(num_layers):\n","            layers.append(BottleneckBlock(in_channels + i * growth_rate, growth_rate))\n","        self.block = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.block(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMwlDUAOfoWi"},"outputs":[],"source":["class DenseNet(nn.Module):\n","    def __init__(self, num_blocks, growth_rate, num_classes):\n","        super(DenseNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 2 * growth_rate, kernel_size=7, padding=3, stride=2, bias=False)\n","        self.bn1 = nn.BatchNorm2d(2 * growth_rate)\n","        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.dense_blocks = nn.ModuleList()\n","        in_channels = 2 * growth_rate\n","        for i, num_layers in enumerate(num_blocks):\n","            self.dense_blocks.append(DenseBlock(num_layers, in_channels, growth_rate))\n","            in_channels += num_layers * growth_rate\n","            if i != len(num_blocks) - 1:\n","                out_channels = in_channels // 2\n","                self.dense_blocks.append(nn.Sequential(\n","                    nn.BatchNorm2d(in_channels),\n","                    nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n","                    nn.AvgPool2d(kernel_size=2, stride=2)\n","                ))\n","                in_channels = out_channels\n","\n","        self.bn2 = nn.BatchNorm2d(in_channels)\n","        self.pool2 = nn.AvgPool2d(kernel_size=7)\n","        self.relu = nn.ReLU()\n","        self.fc = nn.Linear(in_channels, num_classes)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.pool1(x)\n","\n","        for block in self.dense_blocks:\n","            x = block(x)\n","\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        x = self.pool2(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ltB3OKvvLjN"},"outputs":[],"source":["n_classes = len(list(classes.keys()))\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = DenseNet(\n","    [6, 12, 24, 16],\n","    growth_rate=32,\n","    num_classes=n_classes\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaHaED-Pv4Z8"},"outputs":[],"source":["model.eval()\n","\n","dummy_tensor = torch.randn(1, 3, 224, 224).to(device)\n","\n","with torch.no_grad():\n","    output = model(dummy_tensor)\n","\n","print('Output shape:', output.shape)"]},{"cell_type":"markdown","metadata":{"id":"BwUyHR5Ry8Ma"},"source":["## 8. Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6yK8gbkEjY4"},"outputs":[],"source":["def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    losses = []\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            losses.append(loss.item())\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    loss = sum(losses) / len(losses)\n","    acc = correct / total\n","\n","    return loss, acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHlJ41gzlD73"},"outputs":[],"source":["def fit(\n","    model,\n","    train_loader,\n","    val_loader,\n","    criterion,\n","    optimizer,\n","    device,\n","    epochs\n","):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        batch_train_losses = []\n","\n","        model.train()\n","        for idx, (inputs, labels) in enumerate(train_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            batch_train_losses.append(loss.item())\n","\n","        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n","        train_losses.append(train_loss)\n","\n","        val_loss, val_acc = evaluate(\n","            model, val_loader,\n","            criterion, device\n","        )\n","        val_losses.append(val_loss)\n","\n","        print(f'EPOCH {epoch + 1}:\\tTrain loss: {train_loss:.4f}\\tVal loss: {val_loss:.4f}')\n","\n","    return train_losses, val_losses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxIchZovy-nN"},"outputs":[],"source":["lr = 1e-3\n","epochs = 100\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(\n","    model.parameters(),\n","    lr=lr\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fcz64qrvni-6","scrolled":false},"outputs":[],"source":["train_losses, val_losses = fit(\n","    model,\n","    train_loader,\n","    val_loader,\n","    criterion,\n","    optimizer,\n","    device,\n","    epochs\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0KLZhQh74fG"},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n","ax[0].plot(train_losses)\n","ax[0].set_title('Training Loss')\n","ax[0].set_xlabel('Epoch')\n","ax[0].set_ylabel('Loss')\n","ax[1].plot(val_losses, color='orange')\n","ax[1].set_title('Val Loss')\n","ax[1].set_xlabel('Epoch')\n","ax[1].set_ylabel('Loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gQtRoAhDy9NO"},"source":["## 9. Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRiWE-wFqdrp"},"outputs":[],"source":["val_loss, val_acc = evaluate(\n","    model,\n","    val_loader,\n","    criterion,\n","    device\n",")\n","test_loss, test_acc = evaluate(\n","    model,\n","    test_loader,\n","    criterion,\n","    device\n",")\n","\n","print('Evaluation on val/test dataset')\n","print('Val accuracy: ', val_acc)\n","print('Test accuracy: ', test_acc)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python [conda env:thangdd_env] *","language":"python","name":"conda-env-thangdd_env-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}